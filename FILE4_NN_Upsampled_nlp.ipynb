{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oTAc36V-PLCA"
   },
   "source": [
    "## **APPROACH 4**\n",
    "In the previous approach we did not achieve good accuracy because of the imbalance in the dataset.\n",
    " \n",
    "•   Using the pre-processed EDA file created in FILE1-EDA.\n",
    " \n",
    "•   We noticed that raw data(pre-processed) was highly imbalanced, due to which we did not find good results on the model built on them.\n",
    " \n",
    "upsampling the data to see how the model performs.\n",
    "\n",
    "upsampling using SMOTE\n",
    " \n",
    "•   Splitting the dataset into train and test set\n",
    " \n",
    "**MODEL BUILDING:**\n",
    " \n",
    "•   **Model 1**:\n",
    "Building the model on simple Neural Network, we noticed the model was overfitting.\n",
    " \n",
    "•   **Model 2:**\n",
    "  LSTM without pre-trained GloVe embeddings.\n",
    " \n",
    "**• Model 3:**\n",
    "  LSTM with pre-trained GloVe embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "8J3CzVlvZJg6",
    "outputId": "e82780c0-cfd3-4cc6-e9c5-d196a04b916b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kPhRZi8gZKqu"
   },
   "outputs": [],
   "source": [
    "#setting project path\n",
    "import os\n",
    "os.chdir('/content/drive/My Drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "nZbi5SqXZjFN",
    "outputId": "17448e2a-08f8-409a-c081-a2c013b3f27b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Input, Flatten\n",
    "from keras.layers import GRU, LSTM, Bidirectional, GlobalMaxPool1D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import  EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn import metrics\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import imdb\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, GridSearchCV\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.layers import GRU, LSTM, Bidirectional, GlobalMaxPool1D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "df=pd.read_csv('eda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "Hrf-Uh7ihfS3",
    "outputId": "258a23db-dbaf-4733-d013-ce65bc1d26b6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    " \n",
    " \n",
    "warnings.filterwarnings(\"ignore\")\n",
    " \n",
    "MAX_NB_WORDS = 18000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 769\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM =200\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, split=' ')\n",
    "tokenizer.fit_on_texts(df['nndes'].values)\n",
    " \n",
    "X =tokenizer.texts_to_sequences(df['nndes'])\n",
    " \n",
    "X = pad_sequences(X,padding='post',)\n",
    " \n",
    "#Encoding the target column with the label Encoder\n",
    "le = LabelEncoder() \n",
    "Y= pd.DataFrame(le.fit_transform(df['Assignment group']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TdR04juFSfDT"
   },
   "outputs": [],
   "source": [
    "#Split actual test train data ( Raw Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NPTaN5nbSkxe"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X, \n",
    "                                                    Y, \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_z-60cMaSaNV"
   },
   "outputs": [],
   "source": [
    "#Upsampling data With the SMOTE function\n",
    "#Upsampling on the Train data not the test data\n",
    "sm = SMOTE(random_state = 42) \n",
    "   \n",
    "X_res, y_res = sm.fit_resample(X_train_, y_train_) \n",
    "   \n",
    "X_res = pd.DataFrame(X_res) \n",
    "y_res = pd.DataFrame(y_res) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8RGYc5CTS3ND"
   },
   "source": [
    "Here we are spliting the actaul raw data in to the Train and test. \n",
    "Post splitting will upsample on the train data no the test data.\n",
    "Will train the model with the upsampled train data and \n",
    "test the models with the actual raw test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kxWkb8ScTOoC"
   },
   "source": [
    "X_res and y_res is our upsampled train data and \n",
    "\n",
    "X_test_ and y_test_ are out test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "-oGWA7AB9s6r",
    "outputId": "8d96de4d-fe4f-4393-bcf1-fe29edea9635"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X train  (135030, 769)\n",
      "Shape of y train  (135030, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X train \",X_res.shape)\n",
    "print(\"Shape of y train \",y_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "m47KW3W1iB9h",
    "outputId": "e2084be8-06a1-405c-bf97-eefe8e35c25f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X test  (1700, 769)\n",
      "Shape of y test  (1700, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X test \",X_test_.shape)\n",
    "print(\"Shape of y test \",y_test_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "8LOju95f_Xvl",
    "outputId": "1d3e37a2-df7f-4fa1-d241-0b8895f9d8b0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>729</th>\n",
       "      <th>730</th>\n",
       "      <th>731</th>\n",
       "      <th>732</th>\n",
       "      <th>733</th>\n",
       "      <th>734</th>\n",
       "      <th>735</th>\n",
       "      <th>736</th>\n",
       "      <th>737</th>\n",
       "      <th>738</th>\n",
       "      <th>739</th>\n",
       "      <th>740</th>\n",
       "      <th>741</th>\n",
       "      <th>742</th>\n",
       "      <th>743</th>\n",
       "      <th>744</th>\n",
       "      <th>745</th>\n",
       "      <th>746</th>\n",
       "      <th>747</th>\n",
       "      <th>748</th>\n",
       "      <th>749</th>\n",
       "      <th>750</th>\n",
       "      <th>751</th>\n",
       "      <th>752</th>\n",
       "      <th>753</th>\n",
       "      <th>754</th>\n",
       "      <th>755</th>\n",
       "      <th>756</th>\n",
       "      <th>757</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>72</td>\n",
       "      <td>1245</td>\n",
       "      <td>29</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>457</td>\n",
       "      <td>13</td>\n",
       "      <td>159</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>410</td>\n",
       "      <td>908</td>\n",
       "      <td>6498</td>\n",
       "      <td>295</td>\n",
       "      <td>175</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>652</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>51</td>\n",
       "      <td>131</td>\n",
       "      <td>38</td>\n",
       "      <td>92</td>\n",
       "      <td>6</td>\n",
       "      <td>39</td>\n",
       "      <td>399</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>54</td>\n",
       "      <td>300</td>\n",
       "      <td>52</td>\n",
       "      <td>40</td>\n",
       "      <td>2095</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "      <td>40</td>\n",
       "      <td>31</td>\n",
       "      <td>63</td>\n",
       "      <td>54</td>\n",
       "      <td>34</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>190</td>\n",
       "      <td>63</td>\n",
       "      <td>54</td>\n",
       "      <td>193</td>\n",
       "      <td>101</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>98</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>105</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>105</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>98</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>108</td>\n",
       "      <td>12747</td>\n",
       "      <td>12748</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7061</td>\n",
       "      <td>149</td>\n",
       "      <td>549</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>549</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>7061</td>\n",
       "      <td>1991</td>\n",
       "      <td>12093</td>\n",
       "      <td>710</td>\n",
       "      <td>124</td>\n",
       "      <td>56</td>\n",
       "      <td>404</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>83</td>\n",
       "      <td>12094</td>\n",
       "      <td>12095</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1424</td>\n",
       "      <td>1107</td>\n",
       "      <td>418</td>\n",
       "      <td>81</td>\n",
       "      <td>397</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>245</td>\n",
       "      <td>252</td>\n",
       "      <td>81</td>\n",
       "      <td>397</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>245</td>\n",
       "      <td>252</td>\n",
       "      <td>7693</td>\n",
       "      <td>7694</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1    2    3      4      5    6    ...  762  763  764  765  766  767  768\n",
       "0   131    13   26   72   1245     29   13  ...    0    0    0    0    0    0    0\n",
       "1    31    54  300   52     40   2095   31  ...    0    0    0    0    0    0    0\n",
       "2     6    13   21  108  12747  12748    0  ...    0    0    0    0    0    0    0\n",
       "3     7  7061  149  549      2     36    3  ...    0    0    0    0    0    0    0\n",
       "4  1424  1107  418   81    397     12   19  ...    0    0    0    0    0    0    0\n",
       "\n",
       "[5 rows x 769 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZwcW0AyQ_llW"
   },
   "outputs": [],
   "source": [
    "y_res_onehot=pd.DataFrame(pd.get_dummies(y_res[0]).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "RY3Q2_WXBo_e",
    "outputId": "da6b98d1-d000-4a10-ebf9-a45b20e18e30"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135025</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135026</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135027</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135028</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135029</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135030 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0   1   2   3   4   5   6   7   8   9   ...  32  33  34  35  36  37  38  39  40  41\n",
       "0        0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   0\n",
       "1        0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   1   0   0\n",
       "2        1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   0\n",
       "3        1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   0\n",
       "4        1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   0\n",
       "...     ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
       "135025   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   1\n",
       "135026   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   1\n",
       "135027   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   1\n",
       "135028   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   1\n",
       "135029   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   1\n",
       "\n",
       "[135030 rows x 42 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0-WXrHtgCZV0"
   },
   "outputs": [],
   "source": [
    "y_test_onehot=pd.DataFrame(pd.get_dummies(y_test_[0]).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "yw9cm5Oxi2uv",
    "outputId": "cf36bb1a-06b1-4a21-a1a6-1758debec15e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4   5   6   7   8   9   ...  32  33  34  35  36  37  38  39  40  41\n",
       "0      1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   0\n",
       "1      1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   0\n",
       "2      0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   1   0   0   0\n",
       "3      1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   0\n",
       "4      0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   0\n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
       "1695   1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   0\n",
       "1696   0   0   1   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   0\n",
       "1697   1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   0\n",
       "1698   1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   0\n",
       "1699   1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   0   0   0\n",
       "\n",
       "[1700 rows x 42 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ox3Y7azgQJnJ"
   },
   "source": [
    "## **SIMPLE NEURAL NETWROK MODEL WITHOUT PRE TRAINED WEIGHTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yKSArD9UNWEv"
   },
   "outputs": [],
   "source": [
    "#Model buliding\n",
    "#Initialize variables\n",
    "\n",
    "embedding_size=100\n",
    "batch_size =100\n",
    "epochs = 10\n",
    "maxlen=769\n",
    "model = Sequential() #Sequential model\n",
    "\n",
    "model.add(Embedding(MAX_NB_WORDS, embedding_size, input_length=maxlen))  #Init embedding layer with no pretrained wts\n",
    "#embedding layer takes input of vocabulary size i.e 13000, embedding dimension i.e 50 and input sequence i.e number of columns of dataset i.e 300\n",
    "model.add(Flatten()) #Use flatten layer\n",
    "model.add(Dropout(0.5)) #use dropout for regularization\n",
    "model.add(Dense(10)) #Hidden layer\n",
    "model.add(Dropout(0.3)) #use dropout for regularization\n",
    "model.add(Dense(42, activation='sigmoid')) #Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "UGR1ZDvANWN5",
    "outputId": "f9344d6d-2731-4bbd-e18c-48025eacb3d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 769, 100)          1800000   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 76900)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 76900)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                769010    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 42)                462       \n",
      "=================================================================\n",
      "Total params: 2,569,472\n",
      "Trainable params: 2,569,472\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#To see what our model have, number of layer , output shape ,etc\n",
    "#model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NbvA5PNANWZH"
   },
   "outputs": [],
   "source": [
    "#Compile model with optimizer adam, loss as binary cross entropy and metric is accuracy\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "sv3GdIKdNWVh",
    "outputId": "a1d7bd26-9fd7-4434-be39-f4841224a89d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135030 samples, validate on 1700 samples\n",
      "Epoch 1/15\n",
      "135030/135030 [==============================] - 13s 100us/step - loss: 2.4909 - accuracy: 0.3013 - val_loss: 2.4680 - val_accuracy: 0.3782\n",
      "Epoch 2/15\n",
      "135030/135030 [==============================] - 13s 99us/step - loss: 2.4060 - accuracy: 0.3238 - val_loss: 2.3754 - val_accuracy: 0.4171\n",
      "Epoch 3/15\n",
      "135030/135030 [==============================] - 13s 99us/step - loss: 2.3357 - accuracy: 0.3425 - val_loss: 2.4751 - val_accuracy: 0.3759\n",
      "Epoch 4/15\n",
      "135030/135030 [==============================] - 13s 98us/step - loss: 0.8243 - accuracy: 0.1449 - val_loss: 1.1921e-07 - val_accuracy: 0.4476\n",
      "Epoch 5/15\n",
      "135030/135030 [==============================] - 13s 99us/step - loss: 1.1921e-07 - accuracy: 0.0238 - val_loss: 1.1921e-07 - val_accuracy: 0.4476\n",
      "Epoch 6/15\n",
      "135030/135030 [==============================] - 13s 98us/step - loss: 1.1921e-07 - accuracy: 0.0238 - val_loss: 1.1921e-07 - val_accuracy: 0.4476\n",
      "Epoch 7/15\n",
      "135030/135030 [==============================] - 13s 98us/step - loss: 1.1921e-07 - accuracy: 0.0238 - val_loss: 1.1921e-07 - val_accuracy: 0.4476\n",
      "Epoch 8/15\n",
      "135030/135030 [==============================] - 13s 99us/step - loss: 1.1921e-07 - accuracy: 0.0238 - val_loss: 1.1921e-07 - val_accuracy: 0.4476\n",
      "Epoch 9/15\n",
      "135030/135030 [==============================] - 13s 100us/step - loss: 1.1921e-07 - accuracy: 0.0238 - val_loss: 1.1921e-07 - val_accuracy: 0.4476\n",
      "Epoch 10/15\n",
      "135030/135030 [==============================] - 13s 99us/step - loss: 1.1921e-07 - accuracy: 0.0238 - val_loss: 1.1921e-07 - val_accuracy: 0.4476\n",
      "Epoch 11/15\n",
      "135030/135030 [==============================] - 13s 99us/step - loss: 1.1921e-07 - accuracy: 0.0238 - val_loss: 1.1921e-07 - val_accuracy: 0.4476\n",
      "Epoch 12/15\n",
      "135030/135030 [==============================] - 13s 99us/step - loss: 1.1921e-07 - accuracy: 0.0238 - val_loss: 1.1921e-07 - val_accuracy: 0.4476\n",
      "Epoch 13/15\n",
      "135030/135030 [==============================] - 13s 97us/step - loss: 1.1921e-07 - accuracy: 0.0238 - val_loss: 1.1921e-07 - val_accuracy: 0.4476\n",
      "Epoch 14/15\n",
      "135030/135030 [==============================] - 13s 98us/step - loss: 1.1921e-07 - accuracy: 0.0238 - val_loss: 1.1921e-07 - val_accuracy: 0.4476\n",
      "Epoch 15/15\n",
      "135030/135030 [==============================] - 13s 97us/step - loss: 1.1921e-07 - accuracy: 0.0238 - val_loss: 1.1921e-07 - val_accuracy: 0.4476\n"
     ]
    }
   ],
   "source": [
    "#Fitting model to xtrain and ytrain with defined epochs and batch size\n",
    "history= model.fit(\n",
    "  X_res,\n",
    "  y_res_onehot,\n",
    "  batch_size=64,\n",
    "  epochs=15,\n",
    "  validation_data=(X_test_,y_test_onehot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "H01YOocxNWTb",
    "outputId": "418cce1f-e4ce-441b-9ec6-c0cf19cd2dda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700/1700 [==============================] - 0s 49us/step\n",
      "Test accuracy:  0.4476470649242401\n"
     ]
    }
   ],
   "source": [
    "#Evaluate test set and then print accuracy\n",
    "test = model.evaluate(X_test_,y_test_onehot)\n",
    "print('Test accuracy: ', test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "eJgHBs6_nSUY",
    "outputId": "633caf89-20df-4ac9-e93d-8006c726768b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135030/135030 [==============================] - 7s 51us/step\n",
      "Train accuracy:  0.02380952425301075\n"
     ]
    }
   ],
   "source": [
    "#Evaluate train set and then print accuracy\n",
    "train = model.evaluate(X_res, y_res_onehot)\n",
    "print('Train accuracy: ',train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "MZ3t8kukDxtD",
    "outputId": "96ac0440-4436-4a42-e11f-2b2f25667308"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>train acc</th>\n",
       "      <th>test acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.02381</td>\n",
       "      <td>0.447647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Method  train acc  test acc\n",
       "1     NN    0.02381  0.447647"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Store the accuracy results for each model in a dataframe for final comparison\n",
    "results = pd.DataFrame({'Method':['NN'], 'train acc': train[1], 'test acc':test[1]},index={'1'})\n",
    "results = results[['Method', 'train acc','test acc']]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "CaHBb9EVNWRX",
    "outputId": "aa441818-57cd-47f6-f72a-bb0030f71897"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visulaizing accuracies and loss for train and test set\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5UARc8mAG1n1"
   },
   "outputs": [],
   "source": [
    "# keras library import  for Saving and loading model and weights\n",
    "\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "\n",
    "# serialize model to JSON\n",
    "#  the keras model which is trained is defined as 'model' in this example\n",
    "model_json = model.to_json()\n",
    "\n",
    "\n",
    "with open(\"model\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"up_sample_nn.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1c5QmDVaSHFo"
   },
   "source": [
    "### **LSTM WITHOUT PRE TRAINED WEIGHTS**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "3srUBtCCc169",
    "outputId": "57f87cbe-3ce9-4676-b43b-3d9e91b5aaef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 769, 100)          1800000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 769, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 42)                4242      \n",
      "=================================================================\n",
      "Total params: 1,884,642\n",
      "Trainable params: 1,884,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model buliding\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import BatchNormalization, TimeDistributed, Conv1D, MaxPooling1D,SpatialDropout1D\n",
    "\n",
    "max_features=18000\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(max_features, 100,  input_length=maxlen))\n",
    "model2.add(SpatialDropout1D(0.2))\n",
    "model2.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model2.add(Dense(42, activation='softmax'))\n",
    "model2.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['sparse_categorical_accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w2ptWwD_c2Hy"
   },
   "outputs": [],
   "source": [
    "#Compile model with optimizer adam, loss as binary cross entropy and metric is accuracy\n",
    "model2.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "#Define checkpoint, early stop and reduced lr\n",
    "stop = EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=3, min_lr=1e-6, verbose=1, mode=\"min\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "iLoGwm32c2LC",
    "outputId": "e11d7e9c-32c4-4ef1-8eb5-144b1d6fc5e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135030 samples, validate on 1700 samples\n",
      "Epoch 1/5\n",
      "135030/135030 [==============================] - 1939s 14ms/step - loss: 3.7385 - accuracy: 0.0233 - val_loss: 3.7566 - val_accuracy: 0.0247\n",
      "Epoch 2/5\n",
      "135030/135030 [==============================] - 1973s 15ms/step - loss: 3.7382 - accuracy: 0.0233 - val_loss: 3.7389 - val_accuracy: 0.0141\n",
      "Epoch 3/5\n",
      "135030/135030 [==============================] - 1948s 14ms/step - loss: 3.7382 - accuracy: 0.0232 - val_loss: 3.7493 - val_accuracy: 0.0059\n",
      "Epoch 4/5\n",
      "135030/135030 [==============================] - 1964s 15ms/step - loss: 3.7381 - accuracy: 0.0236 - val_loss: 3.7388 - val_accuracy: 0.0047\n",
      "Epoch 5/5\n",
      "135030/135030 [==============================] - 2040s 15ms/step - loss: 3.7382 - accuracy: 0.0233 - val_loss: 3.7302 - val_accuracy: 0.0059\n"
     ]
    }
   ],
   "source": [
    "#Fitting model to xtrain and ytrain with defined epochs and batch size\n",
    "history2 = model2.fit(\n",
    "  X_res,\n",
    "  y_res_onehot,\n",
    "  batch_size=100,\n",
    "  epochs=5,\n",
    "  validation_data=(X_test_,y_test_onehot),\n",
    "  callbacks=[reduce_lr, stop],\n",
    "  verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "4j0EUTLlnQkY",
    "outputId": "34fe7949-9b64-412f-d4f6-7cad09594d18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700/1700 [==============================] - 6s 4ms/step\n",
      "Test accuracy:  0.0058823530562222\n"
     ]
    }
   ],
   "source": [
    "#Evaluate test set and then print accuracy\n",
    "test2 = model2.evaluate(X_test_,y_test_onehot)\n",
    "print('Test accuracy: ', test2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "D5ROGUb6c2Ny",
    "outputId": "5ce3fbb0-000a-42d0-f287-c8d4a765e5c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135030/135030 [==============================] - 506s 4ms/step\n",
      "Train accuracy:  0.02380952425301075\n"
     ]
    }
   ],
   "source": [
    "#Evaluate train set and then print accuracy\n",
    "train2 = model2.evaluate(X_res, y_res_onehot)\n",
    "print('Train accuracy: ', train2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M0PsniFzv0Sj"
   },
   "outputs": [],
   "source": [
    "  X_train=X_res\n",
    "  y_train=y_res_onehot\n",
    "  X_test=X_test_ \n",
    "  y_test=y_test_onehot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "dK8pDqxdJvws",
    "outputId": "1e3c024d-9b55-4287-9143-83b46f4e0355"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>train acc</th>\n",
       "      <th>test acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.02381</td>\n",
       "      <td>0.447647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.02381</td>\n",
       "      <td>0.005882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Method  train acc  test acc\n",
       "1     NN    0.02381  0.447647\n",
       "2   LSTM    0.02381  0.005882"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Store the accuracy results for each model in a dataframe for final comparison\n",
    "tempResultsDf = pd.DataFrame({'Method':['LSTM'], 'train acc': [train2[1]],'test acc':[test2[1]]},index={'2'})\n",
    "results= pd.concat([results, tempResultsDf])\n",
    "results = results[['Method', 'train acc','test acc']]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8dJLdBeFrU08"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "96RwpWJAHqkL",
    "outputId": "0228a038-6d1e-492e-a979-44e315447160"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02432776, 0.02355874, 0.02385339, ..., 0.02325266, 0.0233066 ,\n",
       "        0.02408345],\n",
       "       [0.02432776, 0.02355874, 0.02385339, ..., 0.02325266, 0.0233066 ,\n",
       "        0.02408345],\n",
       "       [0.02432777, 0.02355874, 0.02385339, ..., 0.02325266, 0.0233066 ,\n",
       "        0.02408345],\n",
       "       ...,\n",
       "       [0.02432776, 0.02355874, 0.02385339, ..., 0.02325266, 0.0233066 ,\n",
       "        0.02408345],\n",
       "       [0.02432776, 0.02355874, 0.02385339, ..., 0.02325266, 0.0233066 ,\n",
       "        0.02408345],\n",
       "       [0.02432776, 0.02355874, 0.02385339, ..., 0.02325266, 0.0233066 ,\n",
       "        0.02408345]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for creating classification report\n",
    "predicted = model2.predict(X_test)\n",
    "predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IBirrfqUW3Ve"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBF3aAKIC8Sf"
   },
   "source": [
    "### **LSTM WITH PRE TRAINED WEIGHTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TeQQNa90EAih",
    "outputId": "832ee277-9af3-42c2-f673-8dd97ff107f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/drive/My Drive'"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XegtiL4Wc2TO"
   },
   "outputs": [],
   "source": [
    "#loading the pre-trained glove vectors of dimension size 200\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "max_features=18000\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "glove_file = open('/content/drive/My Drive/glove.6B.200d.txt')\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g6bRVYaNc2R8"
   },
   "outputs": [],
   "source": [
    "#creating a weight matrix\n",
    "embedding_matrix = zeros((max_features, 200))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PtXLPSPHc2Fl"
   },
   "outputs": [],
   "source": [
    "#model building\n",
    "\n",
    "model3 = Sequential()  #Sequential model\n",
    "model3.add(Embedding(max_features, 200, input_length=maxlen, weights=[embedding_matrix], trainable=True)) #Init embedding layer with no pretrained wts \n",
    "model3.add(Dropout(0.5)) #use dropout for regularization embedding_matrix\n",
    "model3.add(LSTM(100,return_sequences=True, dropout=0.4))  #Hidden layer with dropout Here return_sequences=true as I want to get output from all layer than apply global max pool over all the output so that I dont miss out important info\n",
    "model3.add(GlobalMaxPool1D()) #This is to get values from all states and not missing important info\n",
    "model3.add(Dense(42, activation=\"sigmoid\")) #Final dense layer \n",
    "#Note:GlobalMaxPool1D requires output from all lSTMs therfore return_sequences = True, this returns output from all LSTM not just final LSTM \n",
    "#ALso GlobalMaxPool1D takes max of all output in very special way this step is done so that every words wether at start or at he end is given importance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T9gFG3NHGeEA"
   },
   "outputs": [],
   "source": [
    "#Compile model with optimizer adam, loss as binary cross entropy and metric is accuracy\n",
    "model3.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  #optimizer=Adam(lr=0.01),  #best\n",
    "  optimizer='adam',\n",
    "  metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MjHVzBg2GeO5"
   },
   "outputs": [],
   "source": [
    "#Define checkpoint, early stop and reduced lr\n",
    "stop = EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=3, min_lr=1e-6, verbose=1, mode=\"min\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "NWZdROM7GeSV",
    "outputId": "544d7111-6859-46e2-b325-1178f08b21d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135030 samples, validate on 1700 samples\n",
      "Epoch 1/5\n",
      "135030/135030 [==============================] - 3878s 29ms/step - loss: 3.0765 - acc: 0.1641 - val_loss: 2.5614 - val_acc: 0.3406\n",
      "Epoch 2/5\n",
      "135030/135030 [==============================] - 3889s 29ms/step - loss: 2.6608 - acc: 0.2607 - val_loss: 2.3398 - val_acc: 0.3882\n",
      "Epoch 3/5\n",
      "135030/135030 [==============================] - 3911s 29ms/step - loss: 2.4680 - acc: 0.3114 - val_loss: 2.0935 - val_acc: 0.4612\n",
      "Epoch 4/5\n",
      "135030/135030 [==============================] - 3903s 29ms/step - loss: 2.3177 - acc: 0.3510 - val_loss: 2.0126 - val_acc: 0.4735\n",
      "Epoch 5/5\n",
      "135030/135030 [==============================] - 3900s 29ms/step - loss: 2.1935 - acc: 0.3823 - val_loss: 2.0359 - val_acc: 0.4735\n"
     ]
    }
   ],
   "source": [
    "#Fitting model to xtrain and ytrain with defined epochs and batch size\n",
    "#Here I have used requlaization and model performance tech such as reduced lr, check point and early stop\n",
    "\n",
    "history3 = model3.fit(\n",
    "  X_res,\n",
    "  y_res_onehot,\n",
    "  batch_size=64,\n",
    "  epochs=5,\n",
    "  validation_data=(X_test_,y_test_onehot),\n",
    "  callbacks=[reduce_lr, stop],\n",
    "  verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "iAQNbA8rG5wE",
    "outputId": "b252b15d-c692-49c6-faaa-95abd3731d50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700/1700 [==============================] - 10s 6ms/step\n",
      "Test accuracy:  0.4735293984413147\n"
     ]
    }
   ],
   "source": [
    "#Evaluate test set and then print accuracy\n",
    "test3 = model3.evaluate(X_test_, y_test_onehot)\n",
    "print('Test accuracy: ', test3[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "WfJaaejFG5ty",
    "outputId": "cf562ab3-58d7-4f69-ba1a-ce5e47ef940b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135030/135030 [==============================] - 775s 6ms/step\n",
      "Train accuracy:  0.43251869082450867\n"
     ]
    }
   ],
   "source": [
    "#Evaluate train set and then print accuracy\n",
    "train3 = model3.evaluate(X_res,y_res_onehot)\n",
    "print('Train accuracy: ', train3[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J-Xgz9nlQ2DA"
   },
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "table {\n",
    "  font-family: arial, sans-serif;\n",
    "  border-collapse: collapse;\n",
    "  width: 100%;\n",
    "}\n",
    "\n",
    "td, th {\n",
    "  border: 1px solid #dddddd;\n",
    "  text-align: left;\n",
    "  padding: 8px;\n",
    "  font-size:30px;\n",
    "}\n",
    "\n",
    "tr:nth-child(even) {\n",
    "  background-color: #dddddd;\n",
    "}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<h2> NN models peformance with Upsampled data</h2>\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Method</th>\n",
    "    <th>train acc</th>\n",
    "    <th>test acc</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Simple NN</td>\n",
    "    <td>0.02381</td>\n",
    "    <td>0.447647</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>LSTM</td>\n",
    "    <td>0.02381\t</td>\n",
    "    <td>0.005882</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td> LSTM with pretrained weights</td>\n",
    "    <td>0.43251</td>\n",
    "    <td>0.4735</td>\n",
    "  </tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZSJcMRlEQnBg"
   },
   "source": [
    "On Upsampled Data We are seeing very low accuracies , So will try the NN modles with the downSampled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9nV24DXVX4VT"
   },
   "source": [
    "the model's performance is very poor on upsampled data, hence we will try downsampling in the next approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y65jWwDZX3fl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GHr_t45nQy8Y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FILE4-NN_Upsampled_nlp.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
